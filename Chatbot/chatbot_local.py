import os
import json
from typing import List, Dict
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.llms import HuggingFaceHub
from langchain.prompts import PromptTemplate
import gradio as gr
from dotenv import load_dotenv

# Load bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env
load_dotenv()

class MovieChatbot:
    def __init__(self, json_path: str = "data/data_movies.json"):
        """Kh·ªüi t·∫°o chatbot v·ªõi d·ªØ li·ªáu phim t·ª´ file JSON."""
        self.json_path = json_path
        self.vector_store = None
        self.chain = None
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        self.api_key = os.getenv("HUGGINGFACE_API_TOKEN")
        if not self.api_key:
            raise ValueError("Kh√¥ng t√¨m th·∫•y HUGGINGFACE_API_KEY trong file .env")
        
    def load_movie_data(self) -> List[Dict]:
        """T·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu phim t·ª´ file JSON."""
        try:
            with open(self.json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu th√†nh ƒë·ªãnh d·∫°ng ph√π h·ª£p
            movies_list = []
            for movie_id, movie_data in data.items():
                movie_text = f"""
                T√™n phim: {movie_data['title']}
                Th·ªÉ lo·∫°i: {', '.join(movie_data['genre'])}
                ƒê√°nh gi√°: {movie_data['rating'][0]} ({movie_data['rating'][1]} l∆∞·ª£t ƒë√°nh gi√°)
                Tr·∫°ng th√°i: {movie_data['status']}
                S·ªë t·∫≠p: {movie_data['episodes']}
                NƒÉm ph√°t h√†nh: {movie_data['release year']}
                M√¥ t·∫£: {movie_data['description']}
                """
                movies_list.append({
                    'text': movie_text,
                    'metadata': {
                        'movie_id': movie_id,
                        'title': movie_data['title'],
                        'genres': movie_data['genre'],
                        'rating': movie_data['rating'],
                        'status': movie_data['status'],
                        'episodes': movie_data['episodes'],
                        'release_year': movie_data['release year']
                    }
                })
            return movies_list
        except Exception as e:
            print(f"L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}")
            return []

    def create_vector_store(self, save_path: str = "vector_store"):
        """T·∫°o v√† l∆∞u vector store t·ª´ d·ªØ li·ªáu phim."""
        try:
            movies = self.load_movie_data()
            if not movies:
                return
            
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200
            )
            
            texts = []
            metadatas = []
            for movie in movies:
                chunks = text_splitter.split_text(movie['text'])
                texts.extend(chunks)
                metadatas.extend([movie['metadata']] * len(chunks))
            
            #embeddings
            embeddings = HuggingFaceEmbeddings(
                model_name="google/flan-t5-large"
            )
            
            # T·∫°o vector store
            self.vector_store = FAISS.from_texts(
                texts=texts,
                embedding=embeddings,
                metadatas=metadatas
            )
            
            # L∆∞u vector store
            if not os.path.exists(save_path):
                os.makedirs(save_path)
            self.vector_store.save_local(save_path)
            print(f"ƒê√£ l∆∞u vector store t·∫°i: {save_path}")
            
        except Exception as e:
            print(f"L·ªói khi t·∫°o vector store: {str(e)}")

    def load_vector_store(self, load_path: str = "vector_store"):
        """T·∫£i vector store ƒë√£ l∆∞u."""
        try:
            embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
            )
            self.vector_store = FAISS.load_local(
                load_path, embeddings, allow_dangerous_deserialization=True
            )
            print(f"ƒê√£ t·∫£i vector store t·ª´: {load_path}")
        except Exception as e:
            print(f"L·ªói khi t·∫£i vector store: {str(e)}")

    def setup_chain(self, api_key: str):
            """Thi·∫øt l·∫≠p chu·ªói x·ª≠ l√Ω v·ªõi LLM."""
            try:
                llm = HuggingFaceHub(
                    repo_id="google/flan-t5-large",  # Thay v√¨ declare-lab/flan-alpaca-large
                    task="text2text-generation",
                    model_kwargs={"temperature": 0.5, "max_length": 512},
                    huggingfacehub_api_token=api_key
                )
                
                # prompt template
                template = """
                B·∫°n l√† m·ªôt tr·ª£ l√Ω th√¥ng minh chuy√™n v·ªÅ phim ·∫£nh. H√£y tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin phim ƒë∆∞·ª£c cung c·∫•p.
                
                Th√¥ng tin phim:
                {context}
                
                C√¢u h·ªèi: {question}
                
                Tr·∫£ l·ªùi:
                """
                
                prompt = PromptTemplate(
                    template=template,
                    input_variables=["context", "question"]
                )
                
                # T·∫°o chain
                self.chain = ConversationalRetrievalChain.from_llm(
                    llm=llm,
                    retriever=self.vector_store.as_retriever(
                        search_kwargs={"k": 3}
                    ),
                    memory=self.memory,
                    combine_docs_chain_kwargs={"prompt": prompt}
                )
                return True
                
            except Exception as e:
                print(f"L·ªói khi thi·∫øt l·∫≠p chain: {str(e)}")
                return False

    def chat(self, question: str, history: List[List[str]] = None) -> str:
        """X·ª≠ l√Ω c√¢u h·ªèi v√† tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi."""
        if not self.chain:
            return "Vui l√≤ng thi·∫øt l·∫≠p API key tr∆∞·ªõc khi chat."
        
        try:
            response = self.chain.invoke({"question": question})
            return response['answer']
        except Exception as e:
            return f"L·ªói khi x·ª≠ l√Ω c√¢u h·ªèi: {str(e)}"
        
def create_chatbot_interface():
    """T·∫°o giao di·ªán Gradio cho chatbot."""
    try:
        chatbot = MovieChatbot()
        
        # T·∫°o vector store m·ªõi ho·∫∑c t·∫£i t·ª´ file ƒë√£ l∆∞u
        if not os.path.exists("vector_store"):
            print("ƒêang t·∫°o vector store m·ªõi...")
            chatbot.create_vector_store()
        else:
            print("ƒêang t·∫£i vector store ƒë√£ l∆∞u...")
            chatbot.load_vector_store()
        
        # Thi·∫øt l·∫≠p chain 
        if not chatbot.setup_chain(chatbot.api_key):
            raise ValueError("Kh√¥ng th·ªÉ thi·∫øt l·∫≠p chain v·ªõi API key")
        
        # T·∫°o giao di·ªán Gradio
        with gr.Blocks(title="Chatbot Phim", theme=gr.themes.Soft()) as demo:
            gr.Markdown("""
            # ü§ñ OtakuBot
            Chatbot n√†y c√≥ th·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ phim d·ª±a tr√™n d·ªØ li·ªáu phim c√≥ s·∫µn.
            
            ### C√°c t√≠nh nƒÉng:
            - T√¨m ki·∫øm th√¥ng tin phim
            - G·ª£i √Ω phim theo th·ªÉ lo·∫°i
            - Xem ƒë√°nh gi√° v√† m√¥ t·∫£ phim
            """)
            
            chatbot_interface = gr.ChatInterface(
                fn=chatbot.chat,
                title="Chat v·ªõi Bot",
                description="Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ anime...",
                examples=[
                    "K·ªÉ cho t√¥i v·ªÅ phim One Piece",
                    "C√≥ nh·ªØng phim boylove n√†o ƒëang chi·∫øu?",
                    "Phim n√†o c√≥ rating cao nh·∫•t?",
                    "T√¨m phim c√≥ th·ªÉ lo·∫°i H·ªçc ƒë∆∞·ªùng"
                ],
                theme=gr.themes.Soft()
            )
        
        return demo
    except Exception as e:
        print(f"L·ªói khi kh·ªüi t·∫°o chatbot: {str(e)}")
        return None

def main():
    demo = create_chatbot_interface()
    if demo:
        demo.launch(share=True)
    else:
        print("Kh√¥ng th·ªÉ kh·ªüi t·∫°o chatbot. ")

if __name__ == "__main__":
    main() 